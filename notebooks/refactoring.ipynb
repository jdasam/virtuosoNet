{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from virtuoso import model as modelzoo\n",
    "from virtuoso import model_parameters as param\n",
    "from omegaconf import OmegaConf\n",
    "import _pickle as pickle\n",
    "import sys\n",
    "import yaml\n",
    "from virtuoso import parser\n",
    "\n",
    "sys.modules['model_parameters'] = param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.get_parser()\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = OmegaConf.create(dict)\n",
    "with open('isgn_param.yml', 'w') as f:\n",
    "    yaml.dump(dict, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modelzoo.ISGN(conf, 'cpu')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('isgn_param.yml', 'r') as f:\n",
    "    yaml_obj = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"isgn_param.dat\", 'rb') as f:\n",
    "    param = pickle.load(f)\n",
    "with open(\"prime_isgn_best.pth.tar\", 'rb') as f:\n",
    "    weights = torch.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'nn_params': {}, 'training_params':{}}\n",
    "for key in vars(param):\n",
    "    if isinstance(getattr(param,key), param.Param):\n",
    "        dict['nn_params'][key] = {}\n",
    "        for subkey in vars(getattr(param, key)):\n",
    "            dict['nn_params'][key][subkey] = getattr(getattr(param, key), subkey)\n",
    "    elif key == 'training_args':\n",
    "        dict['training_params'][key] = {}\n",
    "        for subkey in vars(param.training_args):\n",
    "            dict['training_params'][key][subkey] = getattr(param.training_args, subkey)\n",
    "    else:\n",
    "        dict['nn_params'][key] = getattr(param, key)\n",
    "\n",
    "dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dict['training_args']\n",
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if 'isgn' in args.modelCode:\n",
    "    MODEL = modelzoo.ISGN(NET_PARAM, device).to(device)\n",
    "elif 'han' in args.modelCode:\n",
    "    if 'ar' in args.modelCode:\n",
    "        step_by_step = True\n",
    "    else:\n",
    "        step_by_step = False\n",
    "    MODEL = modelzoo.HAN_Integrated(NET_PARAM, device, step_by_step).to(device)\n",
    "elif 'trill' in args.modelCode:\n",
    "    MODEL = modelzoo.TrillRNN(NET_PARAM, device).to(device)\n",
    "else:\n",
    "    print('Error: Unclassified model code')\n",
    "    # Model = modelzoo.HAN_VAE(NET_PARAM, device, False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from virtuoso.inference import get_input_from_xml\n",
    "from virtuoso.utils import load_dat\n",
    "\n",
    "input_keys = ('midi_pitch', 'duration', 'beat_importance', 'measure_length', 'qpm_primo',\n",
    "                          'following_rest', 'distance_from_abs_dynamic', 'distance_from_recent_tempo',\n",
    "                          'beat_position', 'xml_position', 'grace_order', 'preceded_by_grace_note',\n",
    "                          'followed_by_fermata_rest', 'pitch', 'tempo', 'dynamic', 'time_sig_vec',\n",
    "                          'slur_beam_vec',  'composer_vec', 'notation', 'tempo_primo', 'note_location')\n",
    "output_keys = ('beat_tempo', 'velocity', 'onset_deviation', 'articulation', 'pedal_refresh_time',\n",
    "                            'pedal_cut_time', 'pedal_at_start', 'pedal_at_end', 'soft_pedal',\n",
    "                            'pedal_refresh', 'pedal_cut')\n",
    "graph_keys = ['onset', 'forward', 'melisma', 'rest', 'voice']\n",
    "stats = load_dat('dataset/stat.dat')\n",
    "score, input, edges, note_locations = get_input_from_xml('test_pieces/bps_5_1/musicxml_cleaned.musicxml', 'Beethoven', input_keys, graph_keys, stats['stats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_stat = load_dat('training_data_stat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats['stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from virtuoso.pyScoreParser.utils import binary_index\n",
    "from virtuoso.pyScoreParser.feature_utils import time_signature_to_vector, pitch_into_vector, cal_beat_importance, note_notation_to_vector, composer_name_to_vec\n",
    "from virtuoso.pyScoreParser.xml_utils import cal_total_xml_length\n",
    "import virtuoso.pyScoreParser.xml_direction_encoding as dir_enc\n",
    "\n",
    "\n",
    "TEM_EMB_TAB=  dir_enc.define_tempo_embedding_table()\n",
    "DYN_EMB_TAB = dir_enc.define_dynamic_embedding_table()\n",
    "def extract_score_features(xml_notes, measure_positions, beats=None, qpm_primo=0, vel_standard=False):\n",
    "    xml_length = len(xml_notes)\n",
    "    # melody_notes = extract_melody_only_from_notes(xml_notes)\n",
    "    features = []\n",
    "\n",
    "    if qpm_primo == 0:\n",
    "        qpm_primo = xml_notes[0].state_fixed.qpm\n",
    "    tempo_primo_word = dir_enc.direction_words_flatten(xml_notes[0].tempo)\n",
    "    if tempo_primo_word:\n",
    "        tempo_primo = dir_enc.dynamic_embedding(tempo_primo_word, dir_enc.define_tempo_embedding_table(), 5)\n",
    "        tempo_primo = tempo_primo[0:2]\n",
    "    else:\n",
    "        tempo_primo = [0, 0]\n",
    "\n",
    "    cresc_words = ['cresc', 'decresc', 'dim']\n",
    "\n",
    "    onset_positions = list(set([note.note_duration.xml_position for note in xml_notes]))\n",
    "    onset_positions.sort()\n",
    "    total_length = cal_total_xml_length(xml_notes)\n",
    "    \n",
    "    class NoteLocation:\n",
    "        def __init__(self):\n",
    "            self.beat = 0\n",
    "    class MusicFeature:\n",
    "        def __init__(self):\n",
    "            self.midi_pitch =0\n",
    "            self.note_location = NoteLocation()\n",
    "\n",
    "    for i in range(xml_length):\n",
    "        note = xml_notes[i]\n",
    "        feature = MusicFeature()\n",
    "        note_position = note.note_duration.xml_position\n",
    "        measure_index = binary_index(measure_positions, note_position)\n",
    "        if measure_index+1 < len(measure_positions):\n",
    "            measure_length = measure_positions[measure_index+1] - measure_positions[measure_index]\n",
    "            # measure_sec_length = measure_seocnds[measure_index+1] - measure_seocnds[measure_index]\n",
    "        else:\n",
    "            measure_length = measure_positions[measure_index] - measure_positions[measure_index-1]\n",
    "            # measure_sec_length = measure_seocnds[measure_index] - measure_seocnds[measure_index-1]\n",
    "        feature.midi_pitch = note.pitch[1]\n",
    "        feature.pitch = pitch_into_vector(note.pitch[1])\n",
    "        feature.duration = note.note_duration.duration / note.state_fixed.divisions\n",
    "\n",
    "        beat_position = (note_position - measure_positions[measure_index]) / measure_length\n",
    "        feature.beat_position = beat_position\n",
    "        feature.beat_importance = cal_beat_importance(beat_position, note.tempo.time_numerator)\n",
    "        feature.measure_length = measure_length / note.state_fixed.divisions\n",
    "        feature.note_location.voice = note.voice\n",
    "        feature.note_location.onset = binary_index(onset_positions, note_position)\n",
    "        feature.xml_position = note.note_duration.xml_position / total_length\n",
    "        feature.grace_order = note.note_duration.grace_order\n",
    "        feature.is_grace_note = int(note.note_duration.is_grace_note)\n",
    "        feature.preceded_by_grace_note = int(note.note_duration.preceded_by_grace_note)\n",
    "        # feature.melody = int(note in melody_notes)\n",
    "\n",
    "        feature.slur_beam_vec = [int(note.note_notations.is_slur_start), int(note.note_notations.is_slur_continue),\n",
    "                                 int(note.note_notations.is_slur_stop), int(note.note_notations.is_beam_start),\n",
    "                                 int(note.note_notations.is_beam_continue), int(note.note_notations.is_beam_stop)]\n",
    "\n",
    "        feature.time_sig_vec = time_signature_to_vector(note.tempo.time_signature)\n",
    "        feature.following_rest = note.following_rest_duration / note.state_fixed.divisions\n",
    "        feature.followed_by_fermata_rest = int(note.followed_by_fermata_rest)\n",
    "\n",
    "        dynamic_words = dir_enc.direction_words_flatten(note.dynamic)\n",
    "        tempo_words = dir_enc.direction_words_flatten(note.tempo)\n",
    "\n",
    "        feature.dynamic = dir_enc.dynamic_embedding(dynamic_words, DYN_EMB_TAB, len_vec=4)\n",
    "        if feature.dynamic[1] != 0:\n",
    "            for rel in note.dynamic.relative:\n",
    "                for word in cresc_words:\n",
    "                    if word in rel.type['type'] or word in rel.type['content']:\n",
    "                        rel_length = rel.end_xml_position - rel.xml_position\n",
    "                        if rel_length == float(\"inf\") or rel_length == 0:\n",
    "                            rel_length = note.state_fixed.divisions * 10\n",
    "                        ratio = (note_position - rel.xml_position) / rel_length\n",
    "                        feature.dynamic[1] *= (ratio+0.05)\n",
    "                        break\n",
    "        if note.dynamic.cresciuto:\n",
    "            feature.cresciuto = (note.dynamic.cresciuto.overlapped +1) / 2\n",
    "            if note.dynamic.cresciuto.type == 'diminuendo':\n",
    "                feature.cresciuto *= -1\n",
    "        else:\n",
    "            feature.cresciuto = 0\n",
    "        feature.dynamic.append(feature.cresciuto)\n",
    "        feature.tempo = dir_enc.dynamic_embedding(tempo_words, TEM_EMB_TAB, len_vec=5)\n",
    "        feature.notation = note_notation_to_vector(note)\n",
    "        feature.qpm_primo = math.log(qpm_primo, 10)\n",
    "        feature.tempo_primo = tempo_primo\n",
    "        feature.note_location.measure = note.measure_number-1\n",
    "        feature.distance_from_abs_dynamic = (note.note_duration.xml_position - note.dynamic.absolute_position) / note.state_fixed.divisions\n",
    "        feature.distance_from_recent_tempo = (note_position - note.tempo.recently_changed_position) / note.state_fixed.divisions\n",
    "        # print(feature.dynamic + feature.tempo)\n",
    "        features.append(feature)\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = extract_score_features(score.xml_notes, score.measure_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in output_keys:\n",
    "    print(stats['stats'][key]['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xml_to_array(xml_notes, features, composer_name, means, stds):\n",
    "    composer_vec = composer_name_to_vec(composer_name)\n",
    "\n",
    "    test_x = []\n",
    "    note_locations = []\n",
    "    for feat in features:\n",
    "        temp_x = [(feat.midi_pitch - means[0][0]) / stds[0][0], (feat.duration - means[0][1]) / stds[0][1],\n",
    "                    (feat.beat_importance-means[0][2])/stds[0][2], (feat.measure_length-means[0][3])/stds[0][3],\n",
    "                   (feat.qpm_primo - means[0][4]) / stds[0][4],(feat.following_rest - means[0][5]) / stds[0][5],\n",
    "                    (feat.distance_from_abs_dynamic - means[0][6]) / stds[0][6],\n",
    "                  (feat.distance_from_recent_tempo - means[0][7]) / stds[0][7] ,\n",
    "                  feat.beat_position, feat.xml_position, feat.grace_order,\n",
    "                    feat.preceded_by_grace_note, feat.followed_by_fermata_rest] \\\n",
    "                   + feat.pitch + feat.tempo + feat.dynamic + feat.time_sig_vec + feat.slur_beam_vec + composer_vec + feat.notation + feat.tempo_primo\n",
    "        # temp_x.append(feat.is_beat)\n",
    "        test_x.append(temp_x)\n",
    "    return test_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted = read_xml_to_array(score.xml_notes, features, 'Beethoven', old_stat[0], old_stat[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = np.asarray(converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = input.squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03164851910161659,\n",
       " -0.03590252749381295,\n",
       " 0.006223060692309712,\n",
       " -0.01259772423479208,\n",
       " 0.04386550496198205]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(new[0,:5] -old[0,:5]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2072, 78)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
